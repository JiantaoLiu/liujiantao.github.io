<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Key of Tao</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Key of Tao">
<meta property="og:url" content="https://old.jiantaoliu.com/index.html">
<meta property="og:site_name" content="Key of Tao">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Key of Tao">
  
    <link rel="alternate" href="/atom.xml" title="Key of Tao" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Key of Tao</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://old.jiantaoliu.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-hello-world" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/01/hello-world/" class="article-date">
  <time datetime="2018-11-01T04:11:35.596Z" itemprop="datePublished">2018-11-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/01/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2018/11/01/hello-world/" data-id="cjsctn6k8000kjgtm4jxeazdn" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-de-wrinkles-by-gan" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/26/de-wrinkles-by-gan/" class="article-date">
  <time datetime="2018-05-26T09:09:24.000Z" itemprop="datePublished">2018-05-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Log/">Log</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/26/de-wrinkles-by-gan/">de-Wrinkles by GAN</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Problem-statement"><a href="#Problem-statement" class="headerlink" title="Problem statement"></a>Problem statement</h1><p>Cloth wrinkles removal with or without human given knowledge.</p>
<h1 id="Proposal"><a href="#Proposal" class="headerlink" title="Proposal"></a>Proposal</h1><p>Original image and human selected wrinkles areas, problem could be treated as restoration or generate task. In case of  human knowledge is not available, segmentation or traditional shade detection algorithm could be applied. Trial test result could be found below.</p>
<h1 id="Potential-improvement"><a href="#Potential-improvement" class="headerlink" title="Potential improvement"></a>Potential improvement</h1><ul>
<li>Dataset prepared with e-comerce clothes rather than ImageNet which is used to generate this results. The results will greatly improved.Iteratively wash the dataset for specific task or enhancement target.</li>
<li>Perform segmentation first to isolate the object to be de-wrinkle, the generated noise will reduce remarkably.</li>
<li>Auto wrinkle area selection with well trained model.</li>
</ul>
<h1 id="Alternative-methods"><a href="#Alternative-methods" class="headerlink" title="Alternative methods"></a>Alternative methods</h1><p>1. Convert RGB to HSV HSB or HSL color space, minimizing the luma or brightness variation. 2. Try to obtain depth information, generate 3D mesh in wrinkles areas from 2D information. Then perform restoration with 3D information.</p>
<h1 id="Additional-output-I-could-offer"><a href="#Additional-output-I-could-offer" class="headerlink" title="*Additional output I could offer:"></a>*Additional output I could offer:</h1><p>1. An API like  deWrinkle(pSrc,pMask), with built-in merged, encrypted and compressed trained DL model, library with DL framework for any target platform. 2.PC demo with GUI, with capability of open an image and select target area get generated output and show result. 3.Android Demo with GUI,with capability of open an image and selected target area and get the generated output and show result. 4.Modifying any traditional image processing algorithm available for this task.</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/t1.png" alt=""> <strong>Figure 1.</strong> (a)Original Image (b)Generated (c)Human Expert (d)Manually selected area <img src="https://jiantaoliu.com/OLDWPIMG/t2.png" alt=""> <strong>Figure 2.</strong> (a)Original Image (b)Generated (c)Human Expert (d)Manually selected area <img src="https://jiantaoliu.com/OLDWPIMG/t3.png" alt=""> <strong>Figure 3.</strong> View in patches (a)Original Image (b)Manually selected area <img src="https://jiantaoliu.com/OLDWPIMG/t7.png" alt=""> <strong>Figure 4.</strong> Zoomed patch detail (a)Original Image (b)Generated(c)Manually selected area<img src="https://jiantaoliu.com/OLDWPIMG/t6.png" alt=""> <strong>Figure 5.</strong> Zoomed patch detail (a)Original Image (b)Generated(c)Manually selected area <img src="https://jiantaoliu.com/OLDWPIMG/t5.png" alt=""> <strong>Figure 6.</strong> Zoomed patch detail (a)Original Image (b)Generated(c)Manually selected area</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>1. Yang C, Lu X, Lin Z, Shechtman E, Wang O, Li H, editors. High-resolution image inpainting using multi-scale neural patch synthesis. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); 2017. 2. Gao R, Grauman K, editors. On-demand learning for deep image restoration. Proc IEEE Conf Comput Vision and Pattern Recognition; 2017. 3. Yeh RA, Chen C, Lim TY, Schwing AG, Hasegawa-Johnson M, Do MN, editors. Semantic image inpainting with deep generative models. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; 2017. 4. Hsu C, Chen F, Wang G, editors. High-Resolution Image Inpainting through Multiple Deep Networks. Vision, Image and Signal Processing (ICVISP), 2017 International Conference on; 2017: IEEE. 5. Cai N, Su Z, Lin Z, Wang H, Yang Z, Ling BW-K. Blind inpainting using the fully convolutional neural network. The Visual Computer. 2017;33(2):249-61. 6. Yu J, Lin Z, Yang J, Shen X, Lu X, Huang TS. Generative Image Inpainting with Contextual Attention. arXiv preprint arXiv:180107892. 2018. 7. Liu G, Reda FA, Shih KJ, Wang T-C, Tao A, Catanzaro B. Image Inpainting for Irregular Holes Using Partial Convolutions. arXiv preprint arXiv:180407723. 2018. 8. Jing M, He B, Lv Y, editors. Cloth Wrinkle Enhancement Based on the Coarse Mesh Simulation2016; Cham: Springer International Publishing.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2018/05/26/de-wrinkles-by-gan/" data-id="cjsctn6k3000ejgtmil2jlae3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-style-transfer" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/05/style-transfer/" class="article-date">
  <time datetime="2018-02-05T09:37:04.000Z" itemprop="datePublished">2018-02-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Log/">Log</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/05/style-transfer/">Style Transfer</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://jiantaoliu.com/OLDWPIMG/LJT.bmp" target="_blank" rel="noopener"><img src="https://jiantaoliu.com/OLDWPIMG/LJT.bmp" alt=""></a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2018/02/05/style-transfer/" data-id="cjsctn6kt001cjgtmh9iaqmyc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-what-the-cnn-is-looking-and-how-it-shifts-the-attention-cam" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/14/what-the-cnn-is-looking-and-how-it-shifts-the-attention-cam/" class="article-date">
  <time datetime="2017-10-14T00:47:32.000Z" itemprop="datePublished">2017-10-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/14/what-the-cnn-is-looking-and-how-it-shifts-the-attention-cam/">What the CNN is looking and how it shifts the attention</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I train a classifier with Caltech256 Dataset which is a challenging set of 256 object categories containing a total of 30607 images, by Tensorflow with CUDA cuDNN equipped. It really works much faster than my i7-7700 CPU even the GPU(GTX1060/6G) is not the flagship level. Every layer of the CNN has the ability of localization, but this ability will kind of ‘lose’ after Fully Connected layers. Some net like Googlenet is using Average Pooling instead of Fully Connected layers to avoid this kind of thing happen (And that is why I use Googlenet in my previous work for ‘people recognition’ not ‘face’). Class Activation Mapping is proposed by a MITGuy Zhou to solve this issue, it is called Class Activation Mapping which makes CNN possible  ‘Discriminative Localization’. And it is transplantable for other network something like AlexNet, VggNet, GoogleNet, and it can slightly improve the performance. I try some of my photos which are not included in Colteach256 Dataset 256 categories, to see if I will get some funny result(It is a modified VGG).  The hot region is Class Activation Mapping highlights the class-specific discriminative regions. (Both classification and localization)</p>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/11-8.png" alt=""> <strong>Figure 1.</strong> In FZU <img src="https://jiantaoliu.com/OLDWPIMG/22-8.png" alt=""> <strong>Figure 2.</strong> In Google <img src="https://jiantaoliu.com/OLDWPIMG/33-8.png" alt=""> <strong>Figure 3.</strong> In Africa <img src="https://jiantaoliu.com/OLDWPIMG/44-8.png" alt=""> <strong>Figure 4.</strong> In Shinjuku <img src="https://jiantaoliu.com/OLDWPIMG/55-6.png" alt=""> <strong>Figure 5.</strong> A NBA <img src="https://jiantaoliu.com/OLDWPIMG/66-3.png" alt=""> <strong>Figure 6.</strong> A girl <img src="https://jiantaoliu.com/OLDWPIMG/77-3.png" alt=""> <strong>Figure 7.</strong> In Stanford University <img src="https://jiantaoliu.com/OLDWPIMG/88-2.png" alt=""> <strong>Figure 8.</strong> In Stanford University <img src="https://jiantaoliu.com/OLDWPIMG/99-2.png" alt=""> <strong>Figure 9.</strong> At intel <img src="https://jiantaoliu.com/OLDWPIMG/10.png" alt=""> <strong>Figure 10.</strong> Iris - 鸢尾花 (The only success predition, since it is in Calteah 256 cats)</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] B. Zhou <em>et al.</em>, “Learning Deep Features for Discriminative Localization.” pp. 2921-2929.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/14/what-the-cnn-is-looking-and-how-it-shifts-the-attention-cam/" data-id="cjsctn6kz001ljgtm69rmvc3d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/">CUDA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caltech256/">Caltech256</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep/">Deep</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cuDNN/">cuDNN</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-a-fast-fourier-color-constancy-algorithm" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/13/a-fast-fourier-color-constancy-algorithm/" class="article-date">
  <time datetime="2017-10-13T14:31:45.000Z" itemprop="datePublished">2017-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Image-Signal-Processing/">Image Signal Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/13/a-fast-fourier-color-constancy-algorithm/">A fast Fourier color constancy algorithm</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>In CVPR 2017 a cool color constancy algorithm is proposed. This algorithm is 250-3000 times faster than state of the art work and achieving 13- 20% reduction in error. As we all know a convolution  color constancy algorithm reducing the white balance finding work to a feature finding work ! The checking white balance work is just like face detection problem! And this is the continue work  of  the convolution  color constancy algorithm. Same as the convolution color constancy algorithm, it takes an input image transform into a log-chroma histogram. Then directly learning how to discriminate between correctly white-balanced images and poorly white-balanced images. But this algorithm will operate in the frequency domain, changing from relatively expensive  large 2D log-chroma plane to a cehap localizaiton samll log-chroma torus. This algorithm can run 700fps in a cell phone. And it is implemented in Google Nexues and Google Pixel phone and the whole Google Photos system.</p>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/11-7.png" alt=""> <strong>Figure 1.</strong> A bizarre color rendered by Leica M9 (CUMGuy by JiantaoLiu) <img src="https://jiantaoliu.com/OLDWPIMG/22-7.png" alt=""> <strong>Figure 2.</strong> As instructed by the author of this algorithm, RAW and JPG will get different results. <img src="https://jiantaoliu.com/OLDWPIMG/33-7.png" alt=""> <strong>Figure 3.</strong> Compare this algorithm with White Patch Retinex, Gray World, and Principal Component Analysis. <img src="https://jiantaoliu.com/OLDWPIMG/44-7.png" alt=""> <strong>Figure 4.</strong> Rendered by Nikon D800 (Chameleon by JiantaoLiu) <img src="https://jiantaoliu.com/OLDWPIMG/55-5.png" alt=""> <strong>Figure 5.</strong> As instructed by the author of this algorithm, RAW and JPG will get different results. <img src="https://jiantaoliu.com/OLDWPIMG/66-2.png" alt=""> <strong>Figure 6.</strong> Compare this algorithm with White Patch Retinex, Gray World, and Principal Component Analysis. <img src="https://jiantaoliu.com/OLDWPIMG/77-2.png" alt=""> <strong>Figure 7. </strong>Author’s reply. He also invents the Lens Blur algorithm for Google Camera.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]J. T. Barron, and Y. T. Tsai, “Fast Fourier Color Constancy,” 2017. [2] Ebner, Marc. White Patch Retinex, Color Constancy. John Wiley &amp; Sons, 2007. ISBN 978-0-470-05829-9. [3] Ebner, Marc. The Gray World Assumption, Color Constancy. John Wiley &amp; Sons, 2007. ISBN 978-0-470-05829-9. [4] Cheng, Dongliang, Dilip K. Prasad, and Michael S. Brown. “Illuminant estimation for color constancy: why spatial-domain methods work and the role of the color distribution.” JOSA A 31.5 (2014): 1049-1058.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/13/a-fast-fourier-color-constancy-algorithm/" data-id="cjsctn6k4000fjgtmps3lcti0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AWB/">AWB</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Auto-White-Balance/">Auto White Balance</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Google/">Google</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matlab/">Matlab</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-image-processing-based-non-contact-vibration-measurements" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/13/image-processing-based-non-contact-vibration-measurements/" class="article-date">
  <time datetime="2017-10-13T05:02:42.000Z" itemprop="datePublished">2017-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Image-Processing/">Image Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/13/image-processing-based-non-contact-vibration-measurements/">Image processing based non contact vibration measurements</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I proposed a brand new framework for damage identification and modal identification. This is a part of my work. I’ve tried marker tracking,digital image correlation, pattern matching( and then tracking the pattern center). They are suitable for certain kind of measurement which deformation or movement is big enough or under a quasi-static  strain problems. They are not good for my work. I required a sub-pixel sensitive measurement technique, and this will out perform the similar work on vibration measurements based on video sequence. To achieve a better result I’ve tried many record device. Including Aptina-MT9P031 programmable machine vision camera,SONY RX10m3 with a powerful 24mm-600mm zoom lens(35mm equivalent)and 1 inch sensor, Nikon D3400,Nikon D3300, Canon 6d,SONY RX100m4,Apple Iphone7 plus,Xiaomi 6. About 200 video clips are recorded and processed in search for better a result.   <strong>To achieve sub-pixel accuracy I got many problems.</strong></p>
<ul>
<li>Noise from camera encoding algorithm.</li>
<li>Noise from background illumination(Sky, Clouds).</li>
<li>Sudden movement, people, animal or vehicle pass through the frame.</li>
<li>Camera vibration, system vibration by wind.</li>
<li>Black level need to be check under every condition.</li>
<li>Artificial noise comes with pixel binding or skipping(If ROI is applied).</li>
<li>Error generated by perspective distortion.</li>
<li>Alignment error of different target object.</li>
</ul>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/11-6.png" alt=""> <strong>Figure 1.</strong> Comparing with industry level high sensitive acceleration sensor.  In door test of a cabon beam. <img src="https://jiantaoliu.com/OLDWPIMG/22-6.png" alt=""> <strong>Figure 2.</strong> Reference point result. <img src="https://jiantaoliu.com/OLDWPIMG/33-6.png" alt=""> <strong>Figure 3.</strong> Footage by Aptina-MT9P031 sensor. <img src="https://jiantaoliu.com/OLDWPIMG/44-6.png" alt=""> <strong>Figure 4.</strong> Result of bot point. <img src="https://jiantaoliu.com/OLDWPIMG/55-4.png" alt=""> <strong>Figure 5.</strong> Selection done by algorithm. <img src="https://jiantaoliu.com/OLDWPIMG/77-1.png" alt=""> <strong>Figure 6.</strong> A blend figure. <img src="https://jiantaoliu.com/OLDWPIMG/88-1.png" alt=""> <strong>Figure 7.</strong> Xiamen WuYuan Bridge. <img src="https://jiantaoliu.com/OLDWPIMG/99-1.png" alt=""> <strong>Figure 8.</strong> Obtaining the ‘gound truth’ vibration signal of the Xiammen WuYuan Bridge <img src="https://jiantaoliu.com/OLDWPIMG/1010.png" alt=""> <strong>Figure 9.</strong> Obtaining the ‘gound truth’ vibration signal of the Xiammen WuYuan Bridge <img src="https://jiantaoliu.com/OLDWPIMG/1111.png" alt=""> <strong>Figure 10.</strong> ‘Gournd truth’ of  six cables on the left <img src="https://jiantaoliu.com/OLDWPIMG/1212.png" alt=""> <strong>Figure 11.</strong> An alignment operation <img src="https://jiantaoliu.com/OLDWPIMG/1313.png" alt=""> <strong>Figure 12.</strong> An indoor experiment of an metal beam,comparing with industry level sensor and BOSCH’s <em>Sensortech</em> BMA220 <img src="https://jiantaoliu.com/OLDWPIMG/1414-e1510550236181.png" alt=""> <strong>Figure 13.</strong> Result of BOSCH’s <em>Sensortech</em> BMA220 <img src="https://jiantaoliu.com/OLDWPIMG/1515.png" alt=""> <strong>Figure 14.</strong> Very good result <img src="https://jiantaoliu.com/OLDWPIMG/1616.png" alt=""> <strong>Figure 15.</strong> In field experiment setup <img src="https://jiantaoliu.com/OLDWPIMG/1717.png" alt=""> <strong>Figure 16.</strong> In field experiment setup <img src="https://jiantaoliu.com/OLDWPIMG/1818.png" alt=""> <strong>Figure 17.</strong> Noise <img src="https://jiantaoliu.com/OLDWPIMG/1919.png" alt=""> <strong>Figure 18.</strong> Good result <img src="https://jiantaoliu.com/OLDWPIMG/2020.png" alt=""> <strong>Figure 19.</strong> Angular correction for more accuracy result <img src="https://jiantaoliu.com/OLDWPIMG/2121.png" alt=""> <strong>Figure 20.</strong> Angular correction for more accuracy result <img src="https://jiantaoliu.com/OLDWPIMG/2222.png" alt=""> <strong>Figure 21.</strong> Bad points selections work done by computer <img src="https://jiantaoliu.com/OLDWPIMG/2323.png" alt=""> <strong>Figure 22.</strong> Very good result in recent work <img src="https://jiantaoliu.com/OLDWPIMG/118_0057.2.jpg" alt=""> <strong>Figure 23.</strong> My daily work</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/13/image-processing-based-non-contact-vibration-measurements/" data-id="cjsctn6ki000wjgtmu5vo1p6d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DHTest/">DHTest</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Image-Processing/">Image Processing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matlab/">Matlab</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OpenCV/">OpenCV</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-a-defogging-algorithm" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/13/a-defogging-algorithm/" class="article-date">
  <time datetime="2017-10-13T02:58:47.000Z" itemprop="datePublished">2017-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Image-Signal-Processing/">Image Signal Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/13/a-defogging-algorithm/">A defogging algorithm</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>SomeAAA of my photos took by Dji drone is under extreme foggy condition, I implement an algorithm proposed by Fujitsu R&amp;D Center Co., Ltd..The workflow of this algorithm is to find the intensity of atmosphere light first (,top 1/1000 bright pixels in the dark channel), then Estimate transition map, it is a function related to a defogging parameters which represent the strength of defogging value and the so called atmosphere light obtained from previous step. Then proceed to defog the images with those value. It works fine when the exposure is even cross the while frame, as we can see in <strong>Figure 2.</strong> . But it will lose many details in shadow area when the dynamic range is wide, it is easy to be noticed in <strong>Figure 4</strong>. and <strong>Figure 6</strong>.. And this method inevitably leads to overall saturation increase no matter what the espouse setting or lighting condition.</p>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/11-5.png" alt=""> <strong>Figure 1.</strong> 500m high over Fuzhou University in a foggy day by a Dji drone. <img src="https://jiantaoliu.com/OLDWPIMG/22-5.png" alt=""> <strong>Figure 2.</strong> After the defogging algorithm. <img src="https://jiantaoliu.com/OLDWPIMG/33-5.png" alt=""> <strong>Figure 3.</strong> Fly above the top of Xiamen HuWeiShan in a foggy morning <img src="https://jiantaoliu.com/OLDWPIMG/44-5.png" alt=""> <strong>Figure 4.</strong> After the defogging algorithm <img src="https://jiantaoliu.com/OLDWPIMG/55-3.png" alt=""> <strong>Figure 5.</strong> 360m sanp from Xiamen Island to HaiCangCoast with heavy haze pollution <img src="https://jiantaoliu.com/OLDWPIMG/66-1.png" alt=""> <strong>Figure 6.</strong> After the defogging algorithm</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]  Z. Tan <em>et al.</em>, “Fast single-image defogging,” <em>Fujitsu Sci. Tech. J,</em> vol. 50, no. 1, pp. 60-65, 2014.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/13/a-defogging-algorithm/" data-id="cjsctn6k1000cjgtmg7i9hi16" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OpenCV/">OpenCV</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-demosaicing-and-denoising-simultaneously" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/12/demosaicing-and-denoising-simultaneously/" class="article-date">
  <time datetime="2017-10-12T14:22:09.000Z" itemprop="datePublished">2017-10-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Image-Signal-Processing/">Image Signal Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/12/demosaicing-and-denoising-simultaneously/">Demosaicing and denoising simultaneously</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Traditionally, we do demosaic and denoise in sequence, and this will inevitable result in more error or abnormal noise. Demosacing and denoising together  with an alternating direction multiplier method (ADMM) is newly proposed I use this algorithm for some of my photos. <strong>Figure 1.</strong> is a photo I took in Tokyo at night.<strong>Figure 6</strong>. is a photo I took in the largest camera shop in the world, it is an indoor condition which has a evenly distributed illumination. Comparing with other doing demosacing and denoising together algorithm (something like FelxISP), I believe it is not good enough for the actual result. Even the author asserts that it is better than FlexISP when the noise level is high. ADMM appears to have soft edges and lose detail of textures (It is very obvious in <strong>Figure 5.</strong> and <strong>Figure 7.</strong>). even introduce artificial color pattern as we can see in <strong>Figure 3.</strong> or <strong>Figure 7.</strong>. ADMM also has a “deep” option which require Caffe to do the deep work and the result will slightly improve. But judging from my eyes, when the noise level is high,in fact FlexISP is still much better than ADMM.</p>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/55-2.png" alt=""> <strong>Figure 1.</strong> A photo I took at night with complex street lighting in Tokyo <img src="https://jiantaoliu.com/OLDWPIMG/66.png" alt=""> <strong>Figure 2.</strong> Light box on the left. <img src="https://jiantaoliu.com/OLDWPIMG/77.png" alt=""> <strong>Figure 3.</strong> Metal cover on the down left. <img src="https://jiantaoliu.com/OLDWPIMG/88.png" alt=""> <strong>Figure 4.</strong> The vanishing point of this frame. <img src="https://jiantaoliu.com/OLDWPIMG/99.png" alt=""> <strong>Figure 5.</strong> The girl’s skirt in the foreground。 <img src="https://jiantaoliu.com/OLDWPIMG/11-4.png" alt=""> <strong>Figure 6.</strong> A photo I took in the world largest camera shop. <img src="https://jiantaoliu.com/OLDWPIMG/22-4.png" alt=""> <strong>Figure 7.</strong> The focusing ring textures and the “gold ring” of Nikon. <img src="https://jiantaoliu.com/OLDWPIMG/33-4.png" alt=""> <strong>Figure 8.</strong> The shoulder screen of Canon. <img src="https://jiantaoliu.com/OLDWPIMG/44-4.png" alt=""> <strong>Figure 9.</strong> The lenses on the shelves at the top left in this frame</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] H. Tan et al., “JOINT DEMOSAICING AND DENOISING OF NOISY BAYER IMAGES WITH ADMM.”[1] H. Tan et al., “JOINT DEMOSAICING AND DENOISING OF NOISY BAYER IMAGES WITH ADMM.” [2] F. Heide et al., “FlexISP: a flexible camera image processing framework,” Acm Transactions on Graphics, vol. 33, no. 6, pp. 231, 2014.[1] F. Heide et al., “FlexISP: a flexible camera image processing framework,” Acm Transactions on Graphics, vol. 33, no. 6, pp. 231, 2014.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/12/demosaicing-and-denoising-simultaneously/" data-id="cjsctn6kf000rjgtmqb5sxadk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Demosaic/">Demosaic</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Denoise/">Denoise</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/FlexISP/">FlexISP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ISP/">ISP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matlab/">Matlab</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-from-bayer-raw-to-image-files" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/12/from-bayer-raw-to-image-files/" class="article-date">
  <time datetime="2017-10-12T12:34:57.000Z" itemprop="datePublished">2017-10-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Image-Signal-Processing/">Image Signal Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/12/from-bayer-raw-to-image-files/">From Bayer raw to image files</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Some of my photos come with a bizarre color which rendered by the built-in algorithm of the camera. <strong>Figure 1.</strong> The photo is taken by Leica M9,  well know for its unpredictable white balance.  <strong>Figure 2.</strong> The photo is taken by Nikon D800, but the lighting condition when the photo was taken is extremely complex. (In the Chicago Shedd Aquarium, with many light sources with different colors,and it is a Chameleon!!)  I try to do what the camera has one under my control. Load raw files the get the black level and the saturation value for each camera. M9 comes with a strange black level = 133. And then I normalized them and get WB gained under my control. Demosaic the Bayer  RGGB pattern with a stupid gradient-corrected linear interpolation. Then check  the camera dependent color space conversion matrix, and convert the camera RGB to sRGB. And finally, do the gamma correction to fix the nonlinear response of our display device.</p>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/11-3.png" alt=""> <strong>Figure 1. </strong> CMUGuy photo  by Leica M9 <img src="https://jiantaoliu.com/OLDWPIMG/22-3.png" alt=""> <strong>Figure 2.</strong> Six major steps in this workflow (Mouth of CMUGuy) <img src="https://jiantaoliu.com/OLDWPIMG/33-3.png" alt=""> <strong>Figure 3. </strong>Chameleon photo by D800 <img src="https://jiantaoliu.com/OLDWPIMG/44-3.png" alt=""> <strong>Figure 4. </strong>Six major steps in this workflow (Eye of the Chameleon )</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/12/from-bayer-raw-to-image-files/" data-id="cjsctn6kd000ojgtm64tanvkv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Demosaic/">Demosaic</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ISP/">ISP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matlab/">Matlab</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/White-Balance/">White Balance</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-deep-segmentation-through-convolutional-feature-learned-by-extra-regularizer" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/09/deep-segmentation-through-convolutional-feature-learned-by-extra-regularizer/" class="article-date">
  <time datetime="2017-10-09T10:02:18.000Z" itemprop="datePublished">2017-10-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/09/deep-segmentation-through-convolutional-feature-learned-by-extra-regularizer/">Deep segmentation through convolutional feature learned by extra regularizer</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>A new kind of loss function, positive-sharing loss is proposed. This loss function comes with an additional regularizer which take more account of the wrong estimation. (Wrong label,  but nonzero ones). I use this technique in some of my works.  <strong>Figure.1</strong> is a footage  snapshot record 168m away from the target which is a street light located in Xiamen No. 226 LianQian West Rd. The column edge is nicely  depicted by the contour. <strong>Figure.4</strong> is a photo taken from my balcony, under a complex condition with several rich texture timbers. And old houses in Xiamen ShaPoWei in the background where other common methods fail to figure them out. CNN architecture: Input layer-&gt;COV1-&gt;COV2-&gt;COV3-&gt;COV4-&gt;FC1(Fed into a structured forest classifier)-&gt;FC2. Modified from Caffe.</p>
<h1 id="Figures"><a href="#Figures" class="headerlink" title="Figures"></a>Figures</h1><p><img src="https://jiantaoliu.com/OLDWPIMG/00.png" alt=""> <strong>Figure.1 </strong>Footage record 168m from target(Xiamen No. 226 LianQian West Rd street light)<img src="https://jiantaoliu.com/OLDWPIMG/11-2.png" alt=""> <strong>Figure.2 </strong>Comparing deep segmentation results with Canny Prewitt Sobel and Roberts<img src="https://jiantaoliu.com/OLDWPIMG/22-2.png" alt=""></p>
<p><strong>Figure.3 </strong>Randon selection of deep feature maps.</p>
<p><img src="https://jiantaoliu.com/OLDWPIMG/33-2.png" alt=""><strong>Figure.4 </strong>From balcony of home in a sunny day <img src="https://jiantaoliu.com/OLDWPIMG/44-2.png" alt=""></p>
<p><strong>Figure.5 </strong>Comparing deep segmentation results with Canny Prewitt Sobel and Roberts<img src="https://jiantaoliu.com/OLDWPIMG/55-1.png" alt=""></p>
<p><strong>Figure.6 </strong>Randon selection of deep feature maps.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] P. Dollar and C. L. Zitnick. Structured forests for fast edge detection. In Proc. ICCV, pages 1841–1848, 2013.</p>
<p>[2] P. Dollar and C. L. Zitnick. Fast edge detection using structured forests. arXiv preprint arXiv:1406.5549, 2014.</p>
<p>[3] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv: 1408.5093, 2014.</p>
<p>[4] Wei Shen, Xinggang Wang, Yan Wang, Xiang Bai, Zhijiang Zhang. DeepContour: A Deep Convolutional Feature Learned by Positive-sharing Loss for Contour Detection. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, USA, 2015.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://old.jiantaoliu.com/2017/10/09/deep-segmentation-through-convolutional-feature-learned-by-extra-regularizer/" data-id="cjsctn6k7000jjgtmknzg87x6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caffe/">Caffe</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Forest-Classifier/">Forest Classifier</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matlab/">Matlab</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Segmentation/">Segmentation</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Image-Processing/">Image Processing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Image-Signal-Processing/">Image Signal Processing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Knowledge/">Knowledge</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Log/">Log</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AWB/">AWB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AlexNet/">AlexNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Auto-White-Balance/">Auto White Balance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caffe/">Caffe</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caltech256/">Caltech256</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DHTest/">DHTest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep/">Deep</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Demosaic/">Demosaic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Denoise/">Denoise</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Feature/">Feature</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FlexISP/">FlexISP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Forest-Classifier/">Forest Classifier</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google/">Google</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GoogleNet/">GoogleNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HIKVISION/">HIKVISION</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ISP/">ISP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Image-Processing/">Image Processing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Matlab/">Matlab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Motion-magnification/">Motion magnification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OpenCV/">OpenCV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Phase-based/">Phase-based</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transfer-Learning/">Transfer Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/White-Balance/">White Balance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cuDNN/">cuDNN</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/AWB/" style="font-size: 10px;">AWB</a> <a href="/tags/AlexNet/" style="font-size: 10px;">AlexNet</a> <a href="/tags/Auto-White-Balance/" style="font-size: 10px;">Auto White Balance</a> <a href="/tags/CNN/" style="font-size: 11.67px;">CNN</a> <a href="/tags/CUDA/" style="font-size: 10px;">CUDA</a> <a href="/tags/Caffe/" style="font-size: 13.33px;">Caffe</a> <a href="/tags/Caltech256/" style="font-size: 10px;">Caltech256</a> <a href="/tags/DHTest/" style="font-size: 10px;">DHTest</a> <a href="/tags/Deep/" style="font-size: 10px;">Deep</a> <a href="/tags/Deep-Learning/" style="font-size: 11.67px;">Deep Learning</a> <a href="/tags/DeepLearning/" style="font-size: 11.67px;">DeepLearning</a> <a href="/tags/Demosaic/" style="font-size: 11.67px;">Demosaic</a> <a href="/tags/Denoise/" style="font-size: 10px;">Denoise</a> <a href="/tags/Feature/" style="font-size: 10px;">Feature</a> <a href="/tags/FlexISP/" style="font-size: 10px;">FlexISP</a> <a href="/tags/Forest-Classifier/" style="font-size: 10px;">Forest Classifier</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/GoogleNet/" style="font-size: 10px;">GoogleNet</a> <a href="/tags/HIKVISION/" style="font-size: 10px;">HIKVISION</a> <a href="/tags/ISP/" style="font-size: 11.67px;">ISP</a> <a href="/tags/Image-Processing/" style="font-size: 15px;">Image Processing</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Matlab/" style="font-size: 20px;">Matlab</a> <a href="/tags/Motion-magnification/" style="font-size: 10px;">Motion magnification</a> <a href="/tags/OpenCV/" style="font-size: 16.67px;">OpenCV</a> <a href="/tags/Phase-based/" style="font-size: 10px;">Phase-based</a> <a href="/tags/Python/" style="font-size: 18.33px;">Python</a> <a href="/tags/Segmentation/" style="font-size: 10px;">Segmentation</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Transfer-Learning/" style="font-size: 11.67px;">Transfer Learning</a> <a href="/tags/White-Balance/" style="font-size: 10px;">White Balance</a> <a href="/tags/cuDNN/" style="font-size: 10px;">cuDNN</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/01/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/05/26/de-wrinkles-by-gan/">de-Wrinkles by GAN</a>
          </li>
        
          <li>
            <a href="/2018/02/05/style-transfer/">Style Transfer</a>
          </li>
        
          <li>
            <a href="/2017/10/14/what-the-cnn-is-looking-and-how-it-shifts-the-attention-cam/">What the CNN is looking and how it shifts the attention</a>
          </li>
        
          <li>
            <a href="/2017/10/13/a-fast-fourier-color-constancy-algorithm/">A fast Fourier color constancy algorithm</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Jiantao Liu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>